{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook is primarly for gene filtering which encompasses:\n",
    "1. removing noisy time series using autocorrelation of the signal\n",
    "2. removing noisy genes by using SNR across replicates or dynamic time warping across replicates in pseudotime\n",
    "\n",
    "#### Furthermore, the remaining data will be smoothed using some kind of windowed spline:\n",
    "3. The Savitsky-Golay filter will be used to smooth both the control and treatment time series \n",
    "\n",
    "Note: In the R script in this codebase, the abundances and counts given by Kallisto were loaded and the low count genes were already removed from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams.update({'figure.autolayout': True})\n",
    "from copy import deepcopy\n",
    "from scipy.signal import savgol_filter as savgol\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = 'data/tpm_removed_low_count_genes.csv'\n",
    "ntimepts = 12 # ntimepts per trajectory (replicate), 12 for monoculture experiment\n",
    "reps = [0,1,2] \n",
    "df = pd.read_csv(datadir)\n",
    "df_orig = deepcopy(df)\n",
    "nreps = len(reps)\n",
    "sampleLabels = list(df.columns[1:])\n",
    "transcriptIDs = list(df.iloc[:,0])\n",
    "df = df.iloc[:,1:] # first column contains transcriptIDs\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Separate each group (control and treatment) into their own dataframes\n",
    "- Select the indices corresponding to replicates of interest and return the dataframes as rank-3 tensors with each replicate's data in the third dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' The df that is imported in the preprocess function has the following structure\n",
    "    each column is a datapoint with the progression \n",
    "    t1rep1, t1rep2, t1rep3, t1Mrep1, t1Mrep2, t1Mrep3, t2rep1, ..., t12Mrep3 '''\n",
    "\n",
    "def get_groups_from_df(data,labels): \n",
    "    ''' The df that is imported has the following structure each column is a datapoint with the progression \n",
    "    1rep1, 1rep2, 1rep3, 1Mrep1, 1Mrep2, 1Mrep3, 2rep1, ..., 12Mrep3 .\n",
    "    This functions builds the two matrices (one per group) 1rep1, 1rep2, 1rep3, ..., 12rep1, 12rep2, 12rep3\n",
    "    1Mrep1, 1Mrep3, 1Mrep3, ..., 12Mrep1, 12Mrep2, 12Mrep3 '''\n",
    "    data_c = np.zeros([data.shape[0],int(data.shape[1]/2)]) # c for control\n",
    "    data_t = np.zeros([data.shape[0],int(data.shape[1]/2)]) # t for treatment\n",
    "    c = 0\n",
    "    ct = 0\n",
    "    for i in range(0,data.shape[1]):\n",
    "        if 'M' not in labels[i]: # 'M' stands for malathion (the treatment of group 2) in the labels\n",
    "            data_c[:,c] = data[:,i]\n",
    "            c += 1\n",
    "        elif 'M' in labels[i]:\n",
    "            data_t[:,ct] = data[:,i]\n",
    "            ct += 1\n",
    "    return data_c, data_t\n",
    "\n",
    "def get_reps(reps,ntimepts):\n",
    "    ''' get the columns inds of the replicates to keep. the conditions should already be \n",
    "    separated into their own dataframes/arrays for this to make sense.'''\n",
    "    nreps = 3\n",
    "    allinds = set(list(range(0,ntimepts*nreps)))\n",
    "    if reps == [0]:\n",
    "        keepers = list(allinds - set(list(range(1,ntimepts*nreps,3))) - set(list(range(2,ntimepts*nreps,3))))\n",
    "    elif reps == [1]:\n",
    "        keepers = list(allinds - set(list(range(0,ntimepts*nreps,3))) - set(list(range(2,ntimepts*nreps,3))))\n",
    "    elif reps == [2]:\n",
    "        keepers = list(allinds - set(list(range(0,ntimepts*nreps,3))) - set(list(range(1,ntimepts*nreps,3))))\n",
    "    elif reps == [0,1]: # set subtract column inds for rep3 from allinds\n",
    "        keepers = list(allinds - set(list(range(2,ntimepts*nreps,3)))) # column inds for rep1 and rep2\n",
    "    elif reps == [0,2]: # set subtract column inds for rep2 from allinds\n",
    "        keepers = list(allinds - set(list(range(1,ntimepts*nreps,3)))) # column inds for rep1 and rep3\n",
    "    elif reps == [1,2]: # set subtract column inds for rep1 from allinds\n",
    "        keepers = list(allinds - set(list(range(0,ntimepts*nreps,3))))\n",
    "    elif reps == [0,1,2]:\n",
    "        keepers = list(allinds)\n",
    "    keepers.sort()\n",
    "    return keepers\n",
    "\n",
    "def put_groups_in_3D(data,nTraj,nT):\n",
    "    '''Data from each trajectory (replicate) is placed in a new 2d array which is appended to one 3d array of \n",
    "    dimension n x m x r. n is number of genes, m is number of timepoints, r is number of replicates.'''\n",
    "    X = np.zeros((data.shape[0],nT,nTraj))\n",
    "    reps = list(range(0,nTraj))\n",
    "    for i in reps:\n",
    "        X[:,:,i] = data[:,get_reps([i],nT)]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Smooth the data\n",
    "- Compute distance b/w smoothed and raw time series\n",
    "- Compute autocorrelations of each gene's time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_time_series(data,window_size=3,polyorder=1):\n",
    "    '''Using scipy's Savitsky-Golay filter to smooth the data. window_size must be an odd number \n",
    "    and greater than polyorder'''\n",
    "    return savgol(data,window_size,polyorder,axis=1)\n",
    "\n",
    "def dist_bw_smooth_raw(raw,smooth):\n",
    "    dist = np.linalg.norm(raw-smooth,ord=2,axis=1) / np.linalg.norm(raw,ord=2,axis=1)\n",
    "    mean_dist = np.mean(dist,axis=1)\n",
    "    stdev_dist = np.std(dist,axis=1)\n",
    "    return dist,mean_dist,stdev_dist\n",
    "\n",
    "def acorr(x):\n",
    "    x = x - x.mean()\n",
    "    autocorr = np.correlate(x, x, mode='full')\n",
    "    autocorr /= autocorr.max()\n",
    "    autocorr = autocorr[len(x)-1:]\n",
    "    return autocorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data in desired format\n",
    "data_c, data_t = get_groups_from_df(np.array(df),sampleLabels) \n",
    "data_c, data_t = put_groups_in_3D(data_c,nreps,ntimepts), put_groups_in_3D(data_t,nreps,ntimepts)\n",
    "# first two timepoints are pre-treatment. last timepoint is also anomalous.\n",
    "data_c, data_t = data_c[:,2:-1], data_t[:,2:-1] \n",
    "# background subtract\n",
    "data_bs = np.maximum(data_t - data_c,0.0)\n",
    "# smooth the data with Savitsky-Golay filter\n",
    "window_size = 7 # for savgol_filter\n",
    "polyorder = 3\n",
    "data_c_smooth = smooth_time_series(data_c,window_size=window_size,polyorder=polyorder)\n",
    "data_t_smooth = smooth_time_series(data_t,window_size=window_size,polyorder=polyorder)\n",
    "data_bs_smooth = np.maximum(data_t_smooth - data_c_smooth,0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What do the distances b/w the raw and smooth curves look like? \n",
    "dist_c,mean_dist_c,stdev_dist_c = dist_bw_smooth_raw(data_c,data_c_smooth)\n",
    "dist_t,mean_dist_t,stdev_dist_t = dist_bw_smooth_raw(data_t,data_t_smooth)\n",
    "plt.figure(figsize=(40,10));\n",
    "plt.plot(mean_dist_c,'o')\n",
    "plt.errorbar(list(range(len(mean_dist_c))),mean_dist_c,yerr=stdev_dist_c,fmt='.',ms=0,color='tab:blue',capsize=10,alpha=0.3);\n",
    "plt.figure(figsize=(40,10));\n",
    "plt.plot(mean_dist_t,'o',color='tab:orange')\n",
    "plt.errorbar(list(range(len(mean_dist_t))),mean_dist_t,yerr=stdev_dist_c,fmt='.',ms=0,color='tab:orange',capsize=10,alpha=0.3);\n",
    "# I can't conclude much from this, so I think it may be best to smooth every gene's time series. \n",
    "# Also should we be interpolating to increase the number of timepoints?? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_series(data0,data1,data0smooth,data1smooth,databs,databssmooth,geneidx=0):\n",
    "    '''\n",
    "    Plot raw data (control, treatment, and background subtracted).\n",
    "    Plot smoothed data (control, treatment, and background subtracted).\n",
    "    Plot autocorrelations of raw and smoothed control and treatment.\n",
    "    '''\n",
    "    nrows,ncols=2,3\n",
    "    fig,axs = plt.subplots(nrows,ncols,figsize=(10,4))\n",
    "    for ii in range(data0.shape[2]):\n",
    "        axs[0,0].plot(data0[geneidx,:,ii]);\n",
    "        axs[1,0].plot(data0smooth[geneidx,:,ii]);\n",
    "        axs[0,1].plot(data1[geneidx,:,ii]);\n",
    "        axs[1,1].plot(data1smooth[geneidx,:,ii]);\n",
    "        axs[0,2].plot(databs[geneidx,:,ii]);\n",
    "        axs[1,2].plot(databssmooth[geneidx,:,ii]);\n",
    "    axs[0,0].set_title('Negative control (raw)',fontsize=12)\n",
    "    axs[1,0].set_title('Negative control (filtered)',fontsize=12)\n",
    "    axs[0,1].set_title('Treatment (raw)',fontsize=12)\n",
    "    axs[1,1].set_title('Treatment (filtered)',fontsize=12)\n",
    "    axs[0,2].set_title('bgs (raw)',fontsize=12)\n",
    "    axs[1,2].set_title('filtered data bgs',fontsize=12)\n",
    "    for ii in range(nrows):\n",
    "        axs[ii,0].set_ylabel('TPM')\n",
    "    for jj in range(ncols):\n",
    "        axs[-1,jj].set_xlabel('time point')\n",
    "    plt.tight_layout();\n",
    "\n",
    "    nrows,ncols=4,3\n",
    "    fig,axs = plt.subplots(nrows,ncols,figsize=(10,8))\n",
    "    for ii in range(data0.shape[2]):\n",
    "        axs[0,ii].plot(data0[geneidx,:,ii]);\n",
    "        axs[0,ii].plot(data1[geneidx,:,ii]);\n",
    "        axs[1,ii].plot(data0smooth[geneidx,:,ii]);\n",
    "        axs[1,ii].plot(data1smooth[geneidx,:,ii]);\n",
    "        axs[2,ii].plot(databs[geneidx,:,ii],color='tab:red');\n",
    "        axs[3,ii].plot(databssmooth[geneidx,:,ii],color='tab:red');\n",
    "    axs[0,0].set_title('Replicate 1 (raw)',fontsize=12)\n",
    "    axs[0,1].set_title('Replicate 2 (raw)',fontsize=12)\n",
    "    axs[0,2].set_title('Replicate 3 (raw)',fontsize=12)\n",
    "    axs[1,0].set_title('Replicate 1 (filtered)',fontsize=12)\n",
    "    axs[1,1].set_title('Replicate 2 (filtered)',fontsize=12)\n",
    "    axs[1,2].set_title('Replicate 3 (filtered)',fontsize=12)\n",
    "    axs[2,0].set_title('Replicate 1 (raw) bgs',fontsize=12)\n",
    "    axs[2,1].set_title('Replicate 2 (raw) bgs',fontsize=12)\n",
    "    axs[2,2].set_title('Replicate 3 (raw) bgs',fontsize=12)\n",
    "    axs[3,0].set_title('Replicate 1 (filtered) bgs',fontsize=12)\n",
    "    axs[3,1].set_title('Replicate 2 (filtered) bgs',fontsize=12)\n",
    "    axs[3,2].set_title('Replicate 3 (filtered) bgs',fontsize=12)\n",
    "    for ii in range(nrows):\n",
    "        axs[ii,0].set_ylabel('TPM')\n",
    "    for jj in range(ncols):\n",
    "        axs[-1,jj].set_xlabel('time point')\n",
    "    plt.tight_layout();\n",
    "    \n",
    "    nrows,ncols=2,2\n",
    "    fig,axs = plt.subplots(nrows,ncols,figsize=(10,5))\n",
    "    colors=['C0o','C1o','C2o']\n",
    "    labels=['R1','R2','R3']\n",
    "    for ii in range(data0.shape[2]):\n",
    "        axs[0,0].stem(acorr(data0[geneidx,:,ii]),linefmt='C7',markerfmt=colors[ii],label=labels[ii]);\n",
    "        axs[0,1].stem(acorr(data1[geneidx,:,ii]),linefmt='C7',markerfmt=colors[ii],label=labels[ii]);\n",
    "        axs[1,0].stem(acorr(data0smooth[geneidx,:,ii]),linefmt='C7',markerfmt=colors[ii],label=labels[ii]);\n",
    "        axs[1,1].stem(acorr(data1smooth[geneidx,:,ii]),linefmt='C7',markerfmt=colors[ii],label=labels[ii]);\n",
    "#     plt.xlabel('Lag');\n",
    "#     plt.ylabel('Autocorrelation');\n",
    "    for ii in range(nrows):\n",
    "        axs[ii,0].set_ylabel('Autocorrelation')\n",
    "        axs[-1,ii].set_xlabel('Lag')\n",
    "        for jj in range(2):\n",
    "            axs[ii,jj].legend(fontsize=10);\n",
    "    axs[0,0].set_title('negative control (raw)',fontsize=14)\n",
    "    axs[0,1].set_title('treatment (raw)',fontsize=14)\n",
    "    axs[1,0].set_title('negative control (filtered)',fontsize=14)\n",
    "    axs[1,1].set_title('treatment (filtered)',fontsize=14)\n",
    "    plt.tight_layout();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = np.random.randint(0,len(data_c))\n",
    "plot_single_series(data_c,data_t,data_c_smooth,data_t_smooth,data_bs,data_bs_smooth,geneidx=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Criteria to determine if gene has noisy time series: Autocorrelation at first few lags is very small\n",
    "- Estimation of autocorrelation decreases in accuracy as lag increases, so we consider first few lags only\n",
    "- Should not use autocorrelation of filtered data because any noise passed through a filter will be given a relationship induced by the filter\n",
    "- A note: turns out that a white noise process, when filtered using something like Savitsky-Golay with a large enough window length will transform into a nearly constant signal. This can explain the reasoning behind the genes that were considered to be noisy via the autocorrelation approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrelation_all_data(data):\n",
    "    acorr_all = np.empty((data.shape))\n",
    "    for ii in range(data.shape[0]):\n",
    "        for jj in range(data.shape[2]):\n",
    "            acorr_all[ii,:,jj] = acorr(data[ii,:,jj])\n",
    "    return acorr_all\n",
    "\n",
    "acorr_c,acorr_t = autocorrelation_all_data(data_c),autocorrelation_all_data(data_t)\n",
    "# grab just the first three lags, excluding the zero lag of course. \n",
    "acorr_c,acorr_t = acorr_c[:,1:4,:], acorr_t[:,1:4,:]\n",
    "\n",
    "def autocorrelation_filter(acorr_data,thresh=0.1):\n",
    "    # set autocorrelation to 0.0 if it is less than thresh, otherwise set it to 1.0\n",
    "    acorr_thresh = (np.abs(acorr_data) > thresh)*acorr_data \n",
    "    acorr_thresh[np.abs(acorr_thresh) > 0.0] = 1.0\n",
    "    # if at least L of the autocorrelations (at lags) in each replicate are greater than thresh, \n",
    "    # that gene is labeled as non-noisy. To check this criteria, the sum of each row of acorr_thresh \n",
    "    # should be greater than or equal to L and then sum of the resulting row (sum over each replicate) \n",
    "    # should then be greater than or equal to 3 where boolean matrices are used each step of the way\n",
    "    L = 1\n",
    "    acorr_thresh_sum = np.sum(acorr_thresh,axis=1)  \n",
    "    acorr_thresh_sum = (acorr_thresh_sum >= L) * acorr_thresh_sum\n",
    "    acorr_thresh_sum[acorr_thresh_sum > 0.0] = 1.0\n",
    "    acorr_thresh_sum = np.sum(acorr_thresh_sum,axis=1)\n",
    "    keepers = list((np.nonzero((acorr_thresh_sum == 3) * acorr_thresh_sum))[0]) # 3 as that is # of trajectories\n",
    "    return keepers\n",
    "\n",
    "keepers_acorr_c,keepers_acorr_t = autocorrelation_filter(acorr_c), autocorrelation_filter(acorr_t)\n",
    "keepers_acorr = list(set(keepers_acorr_c) & set(keepers_acorr_t))\n",
    "notkeep_acorr = list(set(list(range(len(df)))) - set(keepers_acorr))\n",
    "print(len(keepers_acorr),len(notkeep_acorr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot a random noisy gene \n",
    "k = random.choice(notkeep_acorr)\n",
    "print(k)\n",
    "plot_single_series(data_c,data_t,data_c_smooth,data_t_smooth,data_bs,data_bs_smooth,geneidx=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot a random non-noisy gene\n",
    "k = random.choice(keepers_acorr)\n",
    "plot_single_series(data_c,data_t,data_c_smooth,data_t_smooth,data_bs,data_bs_smooth,geneidx=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
